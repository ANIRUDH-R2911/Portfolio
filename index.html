<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Anirudh Raghavan - Portfolio</title>
  <link rel="stylesheet" href="style.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" />
</head>
<body>
  <!-- Top Navigation Bar -->
  <nav class="navbar" id="navbar">
    <div class="nav-container">
      <div class="nav-brand">
        <h1>Anirudh Raghavan</h1>
      </div>
      <ul class="nav-menu" id="nav-menu">
        <li><a href="#home" class="nav-link active">Home</a></li>
        <li><a href="#about" class="nav-link">About</a></li>
        <li><a href="#skills" class="nav-link">Skills</a></li>
        <li><a href="#projects" class="nav-link">Projects</a></li>
        <li><a href="#certifications" class="nav-link">Certifications</a></li>
        <li><a href="#publications" class="nav-link">Publications</a></li>
        <li><a href="#contact" class="nav-link">Contact</a></li>
      </ul>
      
      <!-- Mobile Hamburger Button -->
      <button class="hamburger-btn" id="hamburger-btn">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
  </nav>

  <!-- Mobile Menu Overlay -->
  <div class="mobile-overlay" id="mobile-overlay"></div>

  <!-- Main Content -->
  <main class="main-content">
    <!-- Home Section -->
    <section id="home" class="section home-section">
      <div class="intro-container">
        <div class="image-container">
          <img src="Images/Display img.png" alt="Anirudh Raghavan" />
        </div>
        <div class="text-container">
          <h2>ANIRUDH RAGHAVAN</h2>
          <h3>A Bit About Me</h3>
          <p>
            Welcome! I'm Anirudh Raghavan, a graduate student pursuing a Master's degree in Autonomy at Purdue University. My core interest lies in enabling intelligent robotic systems through machine perception, with a focus on Robot Vision and AI. With a strong foundation in Electronics and Communication Engineering from Vellore Institute of Technology, I'm dedicated to developing systems that can perceive, adapt, and respond to dynamic real-world environments. Explore my portfolio to see how I'm bringing these ideas to life.
          </p>
        </div>
      </div>
      
      <div class="home-buttons">
        <a class="resume-button" href="Anirudh_Raghavan_Resume.pdf" target="_blank">
          <i class="fas fa-download"></i> Download Resume
        </a>
        <div class="social-icons">
          <a href="https://www.linkedin.com/in/anirudh-raghavan-232b69266/" class="linkedin" title="LinkedIn">
            <i class="fab fa-linkedin"></i>
          </a>
          <a href="https://github.com/ANIRUDH-R2911" class="github" title="GitHub">
            <i class="fab fa-github"></i>
          </a>
          <a href="mailto:anirudhraghavan2002@gmail.com" class="email" title="Email">
            <i class="fas fa-envelope"></i>
          </a>
        </div>
      </div>
    </section>

    <!-- About Section -->
    <section id="about" class="section about-section">
      <div class="section-header">
        <h2>About Me</h2>
      </div>
      <div class="about-content">
        <p>In 2024, I transitioned from the vibrant city of Chennai to West Lafayette to pursue a Master’s in Autonomy at Purdue University. This journey marked my first experience living independently and has been a transformative year of technical growth, hands-on learning, and personal development.</p><br>
        <p>At Purdue, over the past year, I’ve engaged deeply with robotics and intelligent systems through a blend of theoretical study and applied projects. My recent work includes:</p><br>
        <ul style="list-style-type: circle;">
          <li>Developing a semantic segmentation model using U-Net to classify urban driving scenes, enabling contextual understanding of vehicles, pedestrians, and traffic signals for autonomous systems</li>
          <li>Enhancing object detection robustness in adverse weather conditions by integrating environment-adaptive preprocessing into YOLOv8</li>
          <li>Designing a real-time hand gesture recognition system for robotic arm control using MediaPipe and STM32</li>
        </ul><br>
        <p>Coming from an Electronics and Communication Engineering background at Vellore Institute of Technology, I bring a systems-oriented perspective that bridges embedded systems, machine learning, and control.</p><br>
        <p>Beyond academics, I enjoy walking and observing how both robotic and urban systems interact with their environments. Adapting to life in the Midwest has sparked fresh insights, whether through understanding how intelligent systems perceive the world or how I interpret and navigate unfamiliar surroundings.</p><br>
        <p>I currently work part-time as a student barista at Starbucks, a role that has strengthened my communication, teamwork, and multitasking abilities. Balancing this alongside my academic work has helped me grow both personally and professionally, and I carry these soft skills into every collaborative engineering environment I’m part of.</p><br>
        <p>Curiosity, adaptability, and a passion for purposeful design drive my approach to every challenge, both technical and personal.</p>
      </div>
    </section>

    <!-- Skills Section -->
    <section id="skills" class="section skills-section">
      <div class="section-header">
        <h2>Skills & Expertise</h2>
        <p>Technical proficiencies and tools I work with</p>
      </div>
      <div class="skills-content">
        <p><strong>SOFTWARE</strong> → Arduino IDE, ROS2, Gazebo, Wokwi, Node-Red, LTSpice, Google Firebase, IBM Cloud, MIT App Inventor, Jupyter Notebook, Git</p><br><br>
        <p><strong>OPERATING SYSTEM</strong> → Windows, Linux</p><br><br>
        <p><strong>PROGRAMMING</strong> → Python, C++</p><br><br>
        <p><strong>HARDWARE</strong> → Arduino UNO, Arduino Nano, ESP8266, ESP32, NVIDIA Jetson Nano</p><br><br>
        <p><strong>LIBRARIES/FRAMEWORKS</strong> → YOLO, UNet, OpenCV, MediaPipe, Roboflow, TensorFlow, PyTorch, Pandas, NumPy, Matplotlib, Scikit-learn</p><br><br>
      </div>
    </section>

    <!-- Projects Section -->
    <section id="projects" class="section projects-section">
      <div class="section-header">
        <h2>Projects</h2>
        <p>Explore my work in robotics, AI, and autonomous systems</p>
      </div>
      <div class="projects-grid">
        <!-- Project 1 -->
        <div class="project-card" onclick="window.location.href='project1.html'">
          <div class="project-image">
            <img src="Images/project1.jpg" alt="Project 1" />
            <div class="project-overlay">
              <i class="fas fa-external-link-alt"></i>
            </div>
          </div>
          <div class="project-info">
            <h3>Autonomous Navigation System</h3>
            <p>Advanced robot navigation using computer vision and machine learning</p>
            <div class="project-tags">
              <span class="tag">Computer Vision</span>
              <span class="tag">ROS</span>
              <span class="tag">Python</span>
            </div>
          </div>
        </div>

        <!-- Project 2 -->
        <div class="project-card" onclick="window.location.href='project2.html'">
          <div class="project-image">
            <img src="Images/project2.jpg" alt="Project 2" />
            <div class="project-overlay">
              <i class="fas fa-external-link-alt"></i>
            </div>
          </div>
          <div class="project-info">
            <h3>Smart Surveillance System</h3>
            <p>AI-powered surveillance with real-time object detection and tracking</p>
            <div class="project-tags">
              <span class="tag">Deep Learning</span>
              <span class="tag">OpenCV</span>
              <span class="tag">TensorFlow</span>
            </div>
          </div>
        </div>

        <!-- Project 3 -->
        <div class="project-card" onclick="window.location.href='project3.html'">
          <div class="project-image">
            <img src="Images/project3.jpg" alt="Project 3" />
            <div class="project-overlay">
              <i class="fas fa-external-link-alt"></i>
            </div>
          </div>
          <div class="project-info">
            <h3>Robotic Arm Control</h3>
            <p>Precision control system for industrial robotic applications</p>
            <div class="project-tags">
              <span class="tag">Robotics</span>
              <span class="tag">Control Systems</span>
              <span class="tag">MATLAB</span>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Certifications Section -->
    <section id="certifications" class="section certifications-section">
      <div class="section-header">
        <h2>Certifications</h2>
      </div>
      <div class="certifications-content">
        <p>Certifications content will be added here...</p>
      </div>
    </section>

    <!-- Publications Section -->
    <section id="publications" class="section publications-section">
      <div class="section-header">
        <h2>Publications</h2>
      </div>
      <div class="publications-content">
        <p><strong>TITLE : Design of rubble analyzer probe using ML for earthquake</strong></p><br>
        <p><strong>AUTHORS</strong> : Abhishek Sebastian; R. Pragna; K. Vishal Vythianathan; Dasaraju Sohan Sai; U. Shiva Sri Hari Al; <strong>R. Anirudh</strong>; Apurv Choudhary</p><br>
        <p><strong>CONFERENCE</strong> : 3rd International Conference on Robotics, Intelligent Automation and Control Technologies (RIACT 2022)</p><br>
        <p><strong>PUBLICATION</strong> : AIP Conference Proceedings, 2023 <a href="https://doi.org/10.1063/5.0178244" target="_blank">View Publication</a></p><br><br>
        <p>Designed an earthquake rubble analyzer probe using TinyML and CNN to detect human presence through sounds like “help,” breathing, and coughing with 89.83% accuracy. The system senses ambient audio inside rubble and monitors real-time environmental parameters such as temperature, humidity, pressure, and air quality. Aimed at improving victim detection and survival assessment in post-earthquake rescue operations.</p>
      </div>
    </section>

    <!-- Contact Section -->
    <section id="contact" class="section contact-section">
      <div class="section-header">
        <h2>Get In Touch</h2>
        <p>Let's connect and discuss opportunities in robotics, AI, and autonomous systems</p>
      </div>
      <div class="contact-content">
        <!-- Content will be added later -->
        <p>Contact form and information will be added here...</p>
      </div>
    </section>
  </main>

  <script>
    // Navigation functionality
    const navbar = document.getElementById('navbar');
    const hamburgerBtn = document.getElementById('hamburger-btn');
    const navMenu = document.getElementById('nav-menu');
    const overlay = document.getElementById('mobile-overlay');
    const navLinks = document.querySelectorAll('.nav-link');
    const body = document.body;

    // Mobile menu toggle
    function toggleMobileMenu() {
      navMenu.classList.toggle('nav-menu-open');
      hamburgerBtn.classList.toggle('hamburger-active');
      overlay.classList.toggle('overlay-active');
      body.classList.toggle('no-scroll');
    }

    function closeMobileMenu() {
      navMenu.classList.remove('nav-menu-open');
      hamburgerBtn.classList.remove('hamburger-active');
      overlay.classList.remove('overlay-active');
      body.classList.remove('no-scroll');
    }

    hamburgerBtn.addEventListener('click', toggleMobileMenu);
    overlay.addEventListener('click', closeMobileMenu);

    // Smooth scrolling for navigation links
    navLinks.forEach(link => {
      link.addEventListener('click', function(e) {
        e.preventDefault();
        
        const targetId = this.getAttribute('href').substring(1);
        const targetSection = document.getElementById(targetId);
        
        if (targetSection) {
          const navbarHeight = navbar.offsetHeight;
          const targetPosition = targetSection.offsetTop - navbarHeight;
          
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });
        }
        
        // Close mobile menu if open
        closeMobileMenu();
        
        // Update active link
        navLinks.forEach(l => l.classList.remove('active'));
        this.classList.add('active');
      });
    });

    // Update active navigation on scroll
    window.addEventListener('scroll', function() {
      const scrollPosition = window.scrollY + navbar.offsetHeight + 50;
      
      const sections = document.querySelectorAll('.section');
      sections.forEach(section => {
        const sectionTop = section.offsetTop;
        const sectionHeight = section.offsetHeight;
        const sectionId = section.getAttribute('id');
        
        if (scrollPosition >= sectionTop && scrollPosition < sectionTop + sectionHeight) {
          navLinks.forEach(link => link.classList.remove('active'));
          const activeLink = document.querySelector(`a[href="#${sectionId}"]`);
          if (activeLink) activeLink.classList.add('active');
        }
      });
    });

    // Close mobile menu when window is resized to desktop size
    window.addEventListener('resize', function() {
      if (window.innerWidth > 768) {
        closeMobileMenu();
      }
    });

    // Add loading effect
    window.addEventListener('load', function() {
      document.body.style.opacity = '0';
      setTimeout(() => {
        document.body.style.transition = 'opacity 0.5s ease-in-out';
        document.body.style.opacity = '1';
      }, 100);
    });
  </script>
</body>
</html>